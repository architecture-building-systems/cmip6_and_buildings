{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\Documents\\GitHub\\IPV_Workbench\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os \n",
    "import glob\n",
    "import sys\n",
    "import eppy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from eppy.results import readhtml, fasthtml # the eppy module with functions to read the html\n",
    "import pprint\n",
    "import eppy_multi\n",
    "if sys.platform == 'win32':\n",
    "    module_path = r'C:\\Users\\Justin\\Documents\\GitHub\\IPV_Workbench'\n",
    "else:\n",
    "    module_path = \"/Users/jmccarty/Data/221205_ipv_workbench/github/IPV_Workbench\"\n",
    "print(module_path)\n",
    "sys.path.insert(0, module_path)\n",
    "from ipv_workbench.utilities import utils, time_utils\n",
    "from ipv_workbench.solver import calculations as ipv_calc\n",
    "from ipv_workbench.solver import simple_power_models as ipv_pv\n",
    "from ipv_workbench.translators import mapping_irradiance as ipv_irrad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18005041411595246"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if sys.platform == 'win32':\n",
    "    project_dir = r'C:\\Users\\Justin\\Documents\\GitHub\\cmip6_and_buildings'\n",
    "else:\n",
    "    project_dir = \"/Users/jmccarty/Github/cmip6_an_buildings\"\n",
    "    \n",
    "vintages = ['pre1980', 'post1980', 'new']\n",
    "map_vintages = dict(zip(vintages,[0,1,2]))\n",
    "\n",
    "cz_list = ['1a','2a','2b','3a','3b','3bc','3c','4a','4b',\n",
    "           '4c','5a','5b','6a','6b','7a','8a']\n",
    "map_cz = dict(zip(cz_list,np.arange(0,len(cz_list))))\n",
    "\n",
    "scen_years = eppy_multi.build_scen_years()\n",
    "scen_years = [f'{a}_{b}' for a,b in eppy_multi.build_scen_years()]\n",
    "map_scen_years = dict(zip(scen_years,np.arange(0,len(scen_years))))\n",
    "\n",
    "\n",
    "pv_data_sheet = os.path.join(module_path, 'ipv_workbench', 'devices', 'default_devices', 'cell_module_datasheet.csv')\n",
    "cell_module = pd.read_csv(pv_data_sheet)\n",
    "module_area = cell_module.loc[0]['module_height'] * cell_module.loc[0]['module_width'] / 1e6\n",
    "peak_power = cell_module.loc[0]['Wp']\n",
    "gamma = cell_module.loc[0]['gamma_ref']\n",
    "\n",
    "bldg_types = ['RefBldgFullServiceRestaurant',\n",
    "                'RefBldgHospital',\n",
    "                'RefBldgLargeHotel',\n",
    "                'RefBldgLargeOffice',\n",
    "                'RefBldgMediumOffice',\n",
    "                'RefBldgMidriseApartment',\n",
    "                'RefBldgOutPatient',\n",
    "                'RefBldgPrimarySchool',\n",
    "                'RefBldgQuickServiceRestaurant',\n",
    "                'RefBldgSecondarySchool',\n",
    "                'RefBldgSmallHotel',\n",
    "                'RefBldgSmallOffice',\n",
    "                'RefBldgStand-aloneRetail',\n",
    "                'RefBldgStripMall',\n",
    "                'RefBldgSuperMarket',\n",
    "                'RefBldgWarehouse']\n",
    "map_bldg_type = dict(zip(bldg_types,np.arange(0,len(bldg_types))))\n",
    "\n",
    "def reverse_dict(my_dict):\n",
    "    return dict(zip(my_dict.values(),my_dict.keys()))\n",
    "\n",
    "all_dict = {'vintage':map_vintages,\n",
    "            'vintage_r':reverse_dict(map_vintages),\n",
    "            'cz':map_cz,\n",
    "            'cz_r':reverse_dict(map_cz),\n",
    "            'scen_year':map_scen_years,\n",
    "            'scen_year_r':reverse_dict(map_scen_years),\n",
    "            'bldg_type':map_bldg_type,\n",
    "            'bldg_type_r':reverse_dict(map_bldg_type)}\n",
    "\n",
    "map_perf_metrics = {'hs_el_kwh':13,\n",
    "                    'hs_ng_kwh':14,\n",
    "                    'cs_el_kwh':15,\n",
    "                    'fan_el_kwh':16,\n",
    "                    'fac_ng_kwh':17,\n",
    "                    'fac_el_kwh':18,\n",
    "                    'geff_irrad_kwh':19, \n",
    "                    'cell_temp_degc':20, \n",
    "                    'pv_yield_kwh':21,\n",
    "                    'fac_el_net_kwh':22,\n",
    "                    'pv_consumed_kwh':23, \n",
    "                    'pv_excess_kwh':24,\n",
    "                    'self_suff_pct':25,\n",
    "                    'self_consume_pct':26, \n",
    "                    'op_em_kgco2':27, \n",
    "                    'op_em_pv_kgco2':28, \n",
    "                    'mit_pot_kgco2':29}\n",
    "\n",
    "tables_of_interest = ['Discomfort-weighted Exceedance OccupiedHours', \n",
    "                      'Comfort and Setpoint Not Met Summary',\n",
    "                      'Heat Index OccupiedHours',\n",
    "                      'Unmet Degree-Hours']\n",
    "\n",
    "annual_comfort_metrics = {\n",
    "    'Discomfort-weighted Exceedance OccupiedHours':{\n",
    "\t'Very-cold Exceedance OccupantHours [hr]':0,\n",
    "\t'Cool Exceedance OccupantHours [hr]':1,\n",
    "\t'Warm Exceedance OccupantHours [hr]':2,\n",
    "\t'Very-hot Exceedance OccupantHours [hr]':3},\n",
    "'Comfort and Setpoint Not Met Summary':{\n",
    "\t'Time Setpoint Not Met During Occupied Heating':4,\n",
    "\t'Time Setpoint Not Met During Occupied Cooling':5},\n",
    "'Heat Index OccupiedHours':{\n",
    "\t'Safe (≤ 26.7°C) [hr]':6,\n",
    "\t'Caution (> 26.7°C, ≤ 32.2°C) [hr]':7,\n",
    "\t'Extreme Caution (> 32.2°C, ≤ 39.4°C) [hr]':8,\n",
    "\t'Danger (> 39.4°C, ≤ 51.7°C) [hr]':9,\n",
    "\t'Extreme Danger (> 51.7°C) [hr]':10},\n",
    "'Unmet Degree-Hours':{\n",
    "\t'Cooling Setpoint Unmet Occupied Degree-Hours [°C·hr]':11,\n",
    "\t'Heating Setpoint Unmet Occupied Degree-Hours [°C·hr]':12}\n",
    "}\n",
    "\n",
    "# load up the emissions data for the USA\n",
    "us_emissions = glob.glob(os.path.join(r\"C:\\Users\\Justin\\Documents\\GitHub\\grid_carbon_data\\open_grid\\2019_carbon_accounting_hourly_metric_units\",\"*.csv\"))\n",
    "ba_data = pd.read_excel(r\"C:\\Users\\Justin\\Documents\\GitHub\\grid_carbon_data\\open_grid\\EIA930_Reference_Tables.xlsx\")\n",
    "\n",
    "us_list = []\n",
    "\n",
    "for filepath in us_emissions:\n",
    "    us_list.append(pd.read_csv(filepath)['consumed_co2e_rate_kg_per_mwh_for_electricity'].rename(filepath.split(os.sep)[-1].split(\".\")[0]))\n",
    "    \n",
    "us_grid_data = pd.concat(us_list,axis=1)\n",
    "\n",
    "mean_emissions = []\n",
    "for cz in cz_list:\n",
    "    if cz=='8a':\n",
    "        cz='7a'\n",
    "        cz_name = '8a'\n",
    "    else:\n",
    "        cz_name = cz\n",
    "    ba_codes = ba_data[ba_data['Climate Zone']==cz]['BA Code'].tolist()\n",
    "    get_cols = [c for c in us_grid_data.columns if c in ba_codes]\n",
    "    mean_emissions.append(us_grid_data[get_cols].mean(axis=1).rename(cz_name))\n",
    "    \n",
    "cz_emissions = pd.concat(mean_emissions,axis=1) #gC02e/kWh\n",
    "cz_emissions = cz_emissions / 1000 #kgCO2e/kWh\n",
    "\n",
    "# natural gas co2 factor\n",
    "# https://www.ipcc.ch/site/assets/uploads/2018/03/srccs_annex1-1.pdf\n",
    "ng_factor = 50 #gCO2/MJ\n",
    "ng_factor = ng_factor/0.2777 #0.277 kWh per MJ (g/kWh)\n",
    "ng_factor = ng_factor / 1000 #kgCO2e/kWh\n",
    "ng_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_weather_file(project_dir, scen_year, cz):\n",
    "    if 'historical' in scen_year:\n",
    "        tmy_file = glob.glob(os.path.join(project_dir, 'weather_files', 'tmy3', f'{cz}*'))[0]\n",
    "    else:\n",
    "        scenario = scen_year.split('_')[0]\n",
    "        year = scen_year.split('_')[1]\n",
    "        year_bands = eppy_multi.get_year_bands(year)\n",
    "        tmy_file = os.path.join(project_dir, 'weather_files', 'morphed', cz, scenario, 'EPWs', f'{scenario}_50_{year_bands}.epw')\n",
    "    return tmy_file\n",
    "\n",
    "def get_result_path(project_dir, vintage, cz, scen_year, bldg_type, result_request):\n",
    "    main_result_dir = os.path.join(project_dir, 'eplus_simulations', vintage, 'results')\n",
    "    if result_request=='eplus_tables':\n",
    "        bldg_dir = glob.glob(os.path.join(main_result_dir, 'v22_2', cz, scen_year, f'{bldg_type}*'))[0]\n",
    "        result_file = glob.glob(os.path.join(bldg_dir, '*.htm*'))[0]\n",
    "    \n",
    "    elif result_request=='eplus_timeseries':\n",
    "        bldg_dir = glob.glob(os.path.join(main_result_dir, 'v22_2', cz, scen_year, f'{bldg_type}*'))[0]\n",
    "        result_files = glob.glob(os.path.join(bldg_dir, '*.csv*'))\n",
    "        for f in result_files:\n",
    "            if ('-meter' in f) or ('-ssz' in f) or ('-zsz' in f):\n",
    "                print(result_files)\n",
    "            else:\n",
    "                result_file = f\n",
    "    elif result_request=='irradiance':\n",
    "        bldg_str = os.path.join(main_result_dir, 'pv_results', cz, scen_year, f'{bldg_type}*')\n",
    "        bldg_dir = glob.glob(bldg_str)[0]\n",
    "        result_dir = os.path.join(bldg_dir, 'irrad','annual_irradiance')\n",
    "        grid_path = glob.glob(os.path.join(result_dir, 'model', 'grid','*.pts'))[0]\n",
    "        \n",
    "        direct_ill_path = glob.glob(os.path.join(result_dir, 'results', 'direct','*.ill'))[0]\n",
    "        direct_sun_path = glob.glob(os.path.join(result_dir, 'results', 'direct','sun*.txt'))[0]\n",
    "        \n",
    "        total_ill_path = glob.glob(os.path.join(result_dir, 'results', 'total','*.ill'))[0]\n",
    "        total_sun_path = glob.glob(os.path.join(result_dir, 'results', 'total','sun*.txt'))[0]\n",
    "        \n",
    "        result_file = (grid_path, direct_ill_path, direct_sun_path, total_ill_path, total_sun_path)\n",
    "    else:\n",
    "        print('result_request must be specified as eplus_tables, eplus_timeseries, or irradiance')\n",
    "        result_file = KeyError\n",
    "    return result_file\n",
    "        \n",
    "def compile_sim_code(all_dict, vintage, cz, scen_year, bldg_type):\n",
    "    return f\"{all_dict['vintage'][vintage]}_{all_dict['cz'][cz]}_{all_dict['scen_year'][scen_year]}_{all_dict['bldg_type'][bldg_type]}\"\n",
    "\n",
    "def reverse_sim_code(all_dict, sim_code):\n",
    "    sim_el = sim_code.split(\"_\")\n",
    "    sim_el = [int(e) for e in sim_el]\n",
    "    vintage = all_dict['vintage_r'][sim_el[0]]\n",
    "    cz = all_dict['cz_r'][sim_el[1]]\n",
    "    \n",
    "    scen_year = all_dict['scen_year_r'][0].replace(\"_\",\"-\")\n",
    "    scenario = scen_year.split(\"-\")[0]\n",
    "    year = scen_year.split(\"-\")[1]\n",
    "    bldg_type = all_dict['bldg_type_r'][sim_el[2]]\n",
    "    \n",
    "    return f\"{vintage}_{cz}_{scen_year}_{scenario}_{year}_{bldg_type}\"\n",
    "\n",
    "def get_annual_eplus_results(project_dir, vintage, cz, scen_year, bldg_type, table_name):\n",
    "    fpath = get_result_path(project_dir, vintage, cz, scen_year, bldg_type, 'eplus_tables')\n",
    "    filehandle = open(fpath, 'r') # get a file handle to the html file\n",
    "    named_table = fasthtml.tablebyname(filehandle, table_name)\n",
    "    filehandle.close()\n",
    "    return pd.DataFrame(named_table[1][1:],columns=named_table[1][0]).set_index('',drop=True)\n",
    "\n",
    "def calc_pv_yield(project_dir, vintage, cz, scen_year, bldg_type, module_data):\n",
    "    weather_file = get_weather_file(project_dir, scen_year, cz)\n",
    "    tmy_df = utils.tmy_to_dataframe(weather_file)\n",
    "    tmy_location = utils.tmy_location(weather_file)\n",
    "    \n",
    "    module_area = module_data.loc[0]['module_height'] * module_data.loc[0]['module_width'] / 1e6\n",
    "    peak_power = module_data.loc[0]['Wp']\n",
    "    gamma = module_data.loc[0]['gamma_ref']\n",
    "    \n",
    "    irrad_results = get_result_path(project_dir, vintage, cz, scen_year, bldg_type, 'irradiance')\n",
    "    direct_ill = utils.build_full_ill(irrad_results[2], irrad_results[1]).fillna(0).to_numpy(dtype='float16')\n",
    "    total_ill = utils.build_full_ill(irrad_results[4], irrad_results[3]).fillna(0).to_numpy(dtype='float16')\n",
    "    diffuse_ill =  np.where(total_ill < direct_ill, direct_ill * 0.01, total_ill - direct_ill)\n",
    "    \n",
    "    grid_data = pd.read_csv(irrad_results[0], sep=' ', header=None, \n",
    "                            dtype='float64', names=[\"X\", \"Y\", \"Z\",\n",
    "                                                    \"X_v\", \"Y_v\", \"Z_v\"])\n",
    "    v1_x = grid_data['X_v'].round(6).unique()[0]\n",
    "    v2_x = grid_data['X_v'].round(6).unique()[1]\n",
    "    v1_index = grid_data[grid_data['X_v'].round(6)==v1_x].index\n",
    "    v2_index = grid_data[grid_data['X_v'].round(6)==v2_x].index\n",
    "    v1 = tuple(grid_data.loc[v1_index][['X','Y','Z']].iloc[0].to_list())\n",
    "    v2 = tuple(grid_data.loc[v2_index][['X','Y','Z']].iloc[0].to_list())\n",
    "    \n",
    "    g_eff_v1 = ipv_irrad.calculate_effective_irradiance_timeseries(direct_ill[:,v1_index],\n",
    "                                                    diffuse_ill[:,v1_index],\n",
    "                                                    v1, \n",
    "                                                    np.arange(0,8760),\n",
    "                                                    tmy_location, \n",
    "                                                    tmy_df['atmos_Pa'], \n",
    "                                                    tmy_df['drybulb_C'], \n",
    "                                                    front_cover_color=\"clear\")\n",
    "\n",
    "    g_eff_v2 = ipv_irrad.calculate_effective_irradiance_timeseries(direct_ill[:,v2_index],\n",
    "                                                        diffuse_ill[:,v2_index],\n",
    "                                                        v2, \n",
    "                                                        np.arange(0,8760),\n",
    "                                                        tmy_location, \n",
    "                                                        tmy_df['atmos_Pa'], \n",
    "                                                        tmy_df['drybulb_C'], \n",
    "                                                        front_cover_color=\"clear\")\n",
    "\n",
    "    g_eff_wh_m2 = np.hstack([g_eff_v1, g_eff_v2])\n",
    "    g_eff_kwh = g_eff_wh_m2 * module_area / 1000\n",
    "    g_eff_kwh_array_ts = g_eff_kwh.sum(axis=1)\n",
    "    cell_temp = ipv_calc.calculate_cell_temperature(g_eff_kwh_array_ts,\n",
    "                                                    tmy_df['drybulb_C'],\n",
    "                                                    )\n",
    "\n",
    "    pv_yield_kwh_ts = np.vectorize(ipv_pv.pv_watts_method)(g_eff_kwh_array_ts, cell_temp, peak_power, gamma, T_ref=25, G_ref=1000, I_misc=0.1)\n",
    "    \n",
    "    return g_eff_kwh_array_ts, cell_temp, pv_yield_kwh_ts\n",
    "\n",
    "def convert_joules(j):\n",
    "    return j * 2.77778e-7\n",
    "\n",
    "def create_hourly_results_df(project_dir, eplus_cols, eplus_rename, cell_module, ng_factor, cz_emissions, v, cz, sy, b):\n",
    "    eplus_results = get_result_path(project_dir, v, cz, sy, b, 'eplus_timeseries')\n",
    "    res_df = pd.read_csv(eplus_results, index_col='Date/Time', parse_dates=True)\n",
    "    if 'Heating:NaturalGas [J](Hourly)' in res_df.columns:\n",
    "        pass\n",
    "    else:\n",
    "        res_df['Heating:NaturalGas [J](Hourly)'] = 0\n",
    "    res_df.set_index(utils.ts_8760(),inplace=True)\n",
    "    res_df = convert_joules(res_df[eplus_cols]).rename(columns=dict(zip(eplus_cols, eplus_rename)))\n",
    "    if b=='RefBldgMidriseApartment' or b=='RefBldgMediumOffice':\n",
    "        geff_irrad_kwh, cell_temp_degc, pv_yield_kwh = calc_pv_yield(project_dir, v, cz, sy, b, cell_module)\n",
    "    else:\n",
    "        geff_irrad_kwh, cell_temp_degc, pv_yield_kwh = (np.zeros((8760,)),np.zeros((8760,)),np.zeros((8760,)))\n",
    "\n",
    "    res_df['geff_irrad_kwh'] = geff_irrad_kwh\n",
    "    if type(cell_temp_degc) is np.ndarray:\n",
    "        res_df['cell_temp_degc'] = cell_temp_degc\n",
    "    else:\n",
    "        res_df['cell_temp_degc'] = cell_temp_degc.to_numpy()\n",
    "    res_df['pv_yield_kwh'] = pv_yield_kwh\n",
    "    res_df['fac_el_net_kwh'] = np.clip(res_df['fac_el_kwh'] - res_df['pv_yield_kwh'],0,None)\n",
    "    res_df['pv_consumed_kwh'] = res_df['fac_el_kwh'] - res_df['fac_el_net_kwh']\n",
    "    res_df['pv_excess_kwh'] = np.clip(res_df['fac_el_kwh'] - res_df['pv_yield_kwh'],None,0).abs()\n",
    "    res_df['self_suff_pct'] = np.where(res_df['fac_el_kwh'] == 0, 0, 100 * (res_df['pv_consumed_kwh'] / res_df['fac_el_kwh']))\n",
    "\n",
    "    res_df['self_consume_pct'] = 100 * np.divide(res_df['pv_consumed_kwh'], \n",
    "                                        res_df['pv_yield_kwh'], out=np.zeros_like(res_df['pv_consumed_kwh']), \n",
    "                                        where= res_df['pv_yield_kwh'] != 0)\n",
    "    res_df['op_em_kgco2'] = (res_df['fac_el_kwh'].to_numpy() * cz_emissions[cz].to_numpy()) + (res_df['fac_ng_kwh'] * ng_factor)\n",
    "    res_df['op_em_pv_kgco2'] = (res_df['fac_el_net_kwh'].to_numpy() * cz_emissions[cz].to_numpy()) + (res_df['fac_ng_kwh'] * ng_factor)\n",
    "    res_df['mit_pot_kgco2'] = res_df['op_em_kgco2'] - res_df['op_em_pv_kgco2']\n",
    "    return res_df\n",
    "\n",
    "def create_season_df(df, df_cols, season, sim_code):\n",
    "    season_df = df[df['season_int']==season][df_cols].sum()\n",
    "    season_df['cell_temp_degc'] = df[df['season_int']==season]['cell_temp_degc'].mean()\n",
    "    season_df['self_suff_pct'] = np.where(season_df['fac_el_kwh'] == 0, 0, 100 * (season_df['pv_consumed_kwh'] / season_df['fac_el_kwh']))\n",
    "\n",
    "    season_df['self_consume_pct'] = 100 * np.divide(season_df['pv_consumed_kwh'], \n",
    "                                        season_df['pv_yield_kwh'], out=np.zeros_like(season_df['pv_consumed_kwh']), \n",
    "                                        where= season_df['pv_yield_kwh'] != 0)\n",
    "\n",
    "    return season_df.rename(sim_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PV Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_file = r\"C:\\Users\\Justin\\Documents\\GitHub\\cmip6_and_buildings\\weather_files\\morphed\\1a\\ssp245\\EPWs\\ssp245_50_2020-2050.epw\"\n",
    "tmy_df = utils.tmy_to_dataframe(weather_file)\n",
    "tmy_location = utils.tmy_location(weather_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dir = r\"C:\\Users\\Justin\\Documents\\GitHub\\cmip6_and_buildings\\eplus_simulations\\new\\results\\pv_results\\1a\\ssp245_2035\\RefBldgMidriseApartmentNew2004\\irrad\\annual_irradiance\\results\\total\"\n",
    "direct_dir = r\"C:\\Users\\Justin\\Documents\\GitHub\\cmip6_and_buildings\\eplus_simulations\\new\\results\\pv_results\\1a\\ssp245_2035\\RefBldgMidriseApartmentNew2004\\irrad\\annual_irradiance\\results\\direct\"\n",
    "\n",
    "def get_full_ill(results_dir):\n",
    "    ill_file = glob.glob(os.path.join(results_dir, '*.ill'))[0]\n",
    "    sun_file = glob.glob(os.path.join(results_dir, 'sun*.txt'))[0]\n",
    "    return utils.build_full_ill(sun_file, ill_file)\n",
    "\n",
    "total_ill = get_full_ill(total_dir).fillna(0).to_numpy(dtype='float16')\n",
    "direct_ill = get_full_ill(direct_dir).fillna(0).to_numpy(dtype='float16')\n",
    "diffuse_ill =  np.where(total_ill < direct_ill, direct_ill * 0.01, total_ill - direct_ill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sensor_file = r\"C:\\Users\\Justin\\Documents\\GitHub\\cmip6_and_buildings\\eplus_simulations\\new\\results\\pv_results\\1a\\ssp245_2035\\RefBldgMidriseApartmentNew2004\\irrad\\annual_irradiance\\model\\grid\\RefBldgMidriseApartment.pts\"\n",
    "grid_file = pd.read_csv(sensor_file, sep=' ', header=None, dtype='float64', names=[\"X\", \"Y\", \"Z\", \"X_v\", \"Y_v\", \"Z_v\"])\n",
    "v1_x = grid_file['X_v'].round(6).unique()[0]\n",
    "v2_x = grid_file['X_v'].round(6).unique()[1]\n",
    "v1_index = grid_file[grid_file['X_v'].round(6)==v1_x].index\n",
    "v2_index = grid_file[grid_file['X_v'].round(6)==v2_x].index\n",
    "v1 = tuple(grid_file.loc[v1_index][['X','Y','Z']].iloc[0].to_list())\n",
    "v2 = tuple(grid_file.loc[v2_index][['X','Y','Z']].iloc[0].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_eff_v1 = ipv_irrad.calculate_effective_irradiance_timeseries(direct_ill[:,v1_index],\n",
    "                                                    diffuse_ill[:,v1_index],\n",
    "                                                    v1, \n",
    "                                                    np.arange(0,8760),\n",
    "                                                    tmy_location, \n",
    "                                                    tmy_df['atmos_Pa'], \n",
    "                                                    tmy_df['drybulb_C'], \n",
    "                                                    front_cover_color=\"clear\")\n",
    "\n",
    "g_eff_v2 = ipv_irrad.calculate_effective_irradiance_timeseries(direct_ill[:,v2_index],\n",
    "                                                    diffuse_ill[:,v2_index],\n",
    "                                                    v2, \n",
    "                                                    np.arange(0,8760),\n",
    "                                                    tmy_location, \n",
    "                                                    tmy_df['atmos_Pa'], \n",
    "                                                    tmy_df['drybulb_C'], \n",
    "                                                    front_cover_color=\"clear\")\n",
    "\n",
    "g_eff_wh_m2 = np.hstack([g_eff_v1, g_eff_v2])\n",
    "g_eff_kwh = g_eff_wh_m2 * module_area / 1000\n",
    "g_eff_kwh_array_ts = g_eff_kwh.sum(axis=1)\n",
    "\n",
    "cell_temp = ipv_calc.calculate_cell_temperature(g_eff_kwh_array_ts,\n",
    "                                                tmy_df['drybulb_C'],\n",
    "                                                )\n",
    "\n",
    "pv_yield_kwh_ts = np.vectorize(ipv_pv.pv_watts_method)(g_eff_kwh_array_ts, cell_temp, peak_power, gamma, T_ref=25, G_ref=1000, I_misc=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.2\n"
     ]
    }
   ],
   "source": [
    "calc_pv_yield(project_dir, vintages[0], '1a', 'ssp126_2035',\n",
    "                    'RefBldgMidriseApartment', cell_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPlus Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile annual metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = list(annual_comfort_metrics.keys())\n",
    "annual_results_dict = dict.fromkeys(tables,[])\n",
    "a_ = []\n",
    "b_ = []\n",
    "c_ = []\n",
    "d_ = []\n",
    "\n",
    "for v in vintages:\n",
    "    for cz in cz_list:\n",
    "        for sy in scen_years:\n",
    "            for b in bldg_types: \n",
    "                \n",
    "                sim_code = compile_sim_code(all_dict, v, cz, sy, b)\n",
    "                \n",
    "                for table in tables:\n",
    "                    cols = list(annual_comfort_metrics[table].keys())\n",
    "                    annual_df = get_annual_eplus_results(project_dir, \n",
    "                                                        v, \n",
    "                                                        cz,\n",
    "                                                        sy, \n",
    "                                                        b,\n",
    "                                                        table)\n",
    "                    if table == 'Discomfort-weighted Exceedance OccupiedHours':\n",
    "                        # annual_df = annual_df\n",
    "                        annual_df = annual_df[cols].rename(columns=annual_comfort_metrics[table]).loc['Average'].rename(sim_code)\n",
    "                        a_.append(annual_df)\n",
    "                    elif table == 'Comfort and Setpoint Not Met Summary':\n",
    "                        annual_df = annual_df.transpose()\n",
    "                        annual_df = annual_df[cols].rename(columns=annual_comfort_metrics[table])\n",
    "                        annual_df = annual_df.iloc[0].rename(sim_code)\n",
    "                        b_.append(annual_df)\n",
    "                    elif table == 'Heat Index OccupiedHours':\n",
    "                        annual_df = annual_df[cols].rename(columns=annual_comfort_metrics[table]).loc['Average'].rename(sim_code)\n",
    "                        c_.append(annual_df)\n",
    "                    elif table == 'Unmet Degree-Hours':\n",
    "                        annual_df = annual_df[cols].rename(columns=annual_comfort_metrics[table]).loc['Average'].rename(sim_code)\n",
    "                        d_.append(annual_df)\n",
    "                    else:\n",
    "                        print(\"How did you get there\", table)\n",
    "                        \n",
    "                \n",
    "annual_results = pd.concat([pd.concat(a_,axis=1).transpose(), \n",
    "                            pd.concat(b_,axis=1).transpose(), \n",
    "                            pd.concat(c_,axis=1).transpose(), \n",
    "                            pd.concat(d_,axis=1).transpose()],axis=1)\n",
    "\n",
    "idx = annual_results.index\n",
    "codes = pd.Series(idx).apply(lambda x: reverse_sim_code(all_dict,x)).str.split(\"_\",expand=True)\n",
    "codes = codes.rename(columns=dict(zip([0,1,2,3,4,5],\n",
    "                                      ['vintage','cz','scen_year','scenario','year','bldg_type'])))\n",
    "codes = codes.set_index(idx)\n",
    "annual_results = annual_results.join(codes)\n",
    "\n",
    "annual_results.to_csv(os.path.join('output_data','annual_comfort_data.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Eplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "eplus_cols = ['Heating:Electricity [J](Hourly)',\n",
    "              'Heating:NaturalGas [J](Hourly)',\n",
    "              'Cooling:Electricity [J](Hourly)',\n",
    "              'Fans:Electricity [J](Hourly)',\n",
    "              'NaturalGas:Facility [J](Hourly)',\n",
    "              'Electricity:Facility [J](Hourly)']\n",
    "\n",
    "eplus_rename = ['hs_el_kwh',\n",
    "                'hs_ng_kwh',\n",
    "                'cs_el_kwh',\n",
    "                'fan_el_kwh',\n",
    "                'fac_ng_kwh',\n",
    "                'fac_el_kwh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0_0_0_10'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'result_file' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m bldg_types:\n\u001b[0;32m     12\u001b[0m     sim_code \u001b[39m=\u001b[39m compile_sim_code(all_dict, v, cz, sy, b)\n\u001b[1;32m---> 13\u001b[0m     hour_df \u001b[39m=\u001b[39m create_hourly_results_df(project_dir, eplus_cols, eplus_rename, cell_module, \n\u001b[0;32m     14\u001b[0m                        ng_factor, cz_emissions,v, cz, sy, b)\n\u001b[0;32m     15\u001b[0m     hour_df_cols \u001b[39m=\u001b[39m hour_df\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m     16\u001b[0m     \u001b[39m# hour_df = hour_df.rename(columns=map_perf_metrics).round(4)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[42], line 123\u001b[0m, in \u001b[0;36mcreate_hourly_results_df\u001b[1;34m(project_dir, eplus_cols, eplus_rename, cell_module, ng_factor, cz_emissions, v, cz, sy, b)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_hourly_results_df\u001b[39m(project_dir, eplus_cols, eplus_rename, cell_module, ng_factor, cz_emissions, v, cz, sy, b):\n\u001b[1;32m--> 123\u001b[0m     eplus_results \u001b[39m=\u001b[39m get_result_path(project_dir, v, cz, sy, b, \u001b[39m'\u001b[39m\u001b[39meplus_timeseries\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    124\u001b[0m     res_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(eplus_results, index_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDate/Time\u001b[39m\u001b[39m'\u001b[39m, parse_dates\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    125\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mHeating:NaturalGas [J](Hourly)\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m res_df\u001b[39m.\u001b[39mcolumns:\n",
      "Cell \u001b[1;32mIn[42], line 41\u001b[0m, in \u001b[0;36mget_result_path\u001b[1;34m(project_dir, vintage, cz, scen_year, bldg_type, result_request)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mresult_request must be specified as eplus_tables, eplus_timeseries, or irradiance\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m     result_file \u001b[39m=\u001b[39m \u001b[39mKeyError\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[39mreturn\u001b[39;00m result_file\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'result_file' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "\n",
    "season_dfs = {1:[],\n",
    "              2:[],\n",
    "              3:[],\n",
    "              4:[]}\n",
    "hour_annual_list = []\n",
    "\n",
    "\n",
    "for v in vintages:\n",
    "    for cz in cz_list:\n",
    "        for sy in scen_years[0:1]:\n",
    "            for b in bldg_types:\n",
    "                sim_code = compile_sim_code(all_dict, v, cz, sy, b)\n",
    "                hour_df = create_hourly_results_df(project_dir, eplus_cols, eplus_rename, cell_module, \n",
    "                                   ng_factor, cz_emissions,v, cz, sy, b)\n",
    "                hour_df_cols = hour_df.columns\n",
    "                # hour_df = hour_df.rename(columns=map_perf_metrics).round(4)\n",
    "                hour_df.to_csv(os.path.join('output_data','hourly',f'{sim_code}.csv'))\n",
    "                for season in [1,2,3,4]:   \n",
    "                    hour_df['season_int'] = hour_df.index.month%12 // 3 + 1\n",
    "\n",
    "                    season_labels = {1:'Winter',\n",
    "                                    2:'Spring',\n",
    "                                    3:'Summer',\n",
    "                                    4:'Fall'}\n",
    "                    hour_df['season'] = hour_df['season_int'].map(season_labels)  \n",
    "                    \n",
    "                    season_df = create_season_df(hour_df, hour_df_cols, season, sim_code)\n",
    "                    season_dfs[season].append(season_df)\n",
    "\n",
    "                hour_annual = hour_df[hour_df_cols].sum().rename(sim_code)\n",
    "                hour_annual['cell_temp_degc'] = hour_df['cell_temp_degc'].mean()\n",
    "                hour_annual['self_suff_pct'] = np.where(hour_annual['fac_el_kwh'] == 0, 0, 100 * (hour_annual['pv_consumed_kwh'] / hour_annual['fac_el_kwh']))\n",
    "\n",
    "                hour_annual['self_consume_pct'] = 100 * np.divide(hour_annual['pv_consumed_kwh'], \n",
    "                                                    hour_annual['pv_yield_kwh'], out=np.zeros_like(hour_annual['pv_consumed_kwh']), \n",
    "                                                    where= hour_annual['pv_yield_kwh'] != 0)\n",
    "                hour_annual_list.append(hour_annual)\n",
    "\n",
    "for season in [1,2,3,4]: \n",
    "    season_df = pd.concat(season_dfs[season],axis=1).transpose().rename(columns=map_perf_metrics).round(2)\n",
    "    season_df.to_csv(os.path.join('output_data','seasonal',f'{season_labels[season]}.csv'))\n",
    "\n",
    "hour_annual_all = pd.concat(hour_annual_list,axis=1).transpose().rename(columns=map_perf_metrics).round(2)\n",
    "comfort_df = pd.read_csv(os.path.join('output_data','annual_comfort_data.csv'),index_col='Unnamed: 0')\n",
    "annual_results_data = pd.concat([comfort_df, hour_annual_all],axis=1)\n",
    "annual_results_data.to_csv(os.path.join('output_data','all_annual_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'post1980_2a_historical-2020_historical_2020_RefBldgFullServiceRestaurant'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_sim_code(all_dict,sim_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LBT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b627d637684039ba21c8ca818d908196dc4fef6724760706be784018332fcce1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
